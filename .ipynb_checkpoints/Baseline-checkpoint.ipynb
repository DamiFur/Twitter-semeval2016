{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't import the data as directly downloaded from semeval because it gave me an \"unknown not utf-8 character\" so I imported it as a csv to an Excel and saved it again as train_utf.csv and it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"train_utf.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "testdata = pd.read_csv(\"test_utf.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "\n",
    "## Keep only the abortion tweets\n",
    "is_abortion = traindata['Target']==\"Legalization of Abortion\"\n",
    "is_abortion_test = testdata['Target']==\"Legalization of Abortion\"\n",
    "train_abortion = traindata[is_abortion]\n",
    "test_abortion = testdata[is_abortion_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import unidecode\n",
    "\n",
    "# TweetTokenizer basically unterstands arrows, smiley faces and weird punctuation\n",
    "tokenizer = TweetTokenizer(preserve_case=True, reduce_len=True, strip_handles=False)\n",
    "\n",
    "\n",
    "def my_preprocess(text, keep_hashtags=True):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "\n",
    "    ret = []\n",
    "    for tok in toks:\n",
    "        if tok[0] == \"#\" and not keep_hashtags:\n",
    "            continue\n",
    "        if tok[:4] == \"http\":\n",
    "            continue\n",
    "        if tok[0] == \"@\":\n",
    "            continue\n",
    "        # removing numbers and punctuation\n",
    "        if not tok.isalpha():\n",
    "            continue\n",
    "        ret.append(unidecode.unidecode(tok.lower()))\n",
    "    return \" \".join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Train\n",
    "train_abortion['Text'] = train_abortion['Tweet'].apply(lambda x: my_preprocess(x))\n",
    "\n",
    "# Shifts the order on the original tweet list\n",
    "sample_train = train_abortion.sample(frac=1.0)\n",
    "\n",
    "text_train, label_train = sample_train['Text'], sample_train['Stance']\n",
    "\n",
    "## Test\n",
    "test_abortion['Text'] = test_abortion['Tweet'].apply(lambda x: my_preprocess(x))\n",
    "\n",
    "sample_test = test_abortion.sample(frac=1.0)\n",
    "\n",
    "text_test, label_test = sample_test['Text'], sample_test['Stance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a word count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    binary=True, min_df=0.002, max_df=0.55, ngram_range=(1, 4),\n",
    "    #stop_words=stopwords.words('spanish')\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(pd.concat([text_train,text_test]))\n",
    "X_train = X[:653]\n",
    "X_test = X[653:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple plain old Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.891271056661562"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='l1', class_weight='balanced', C=1.0, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, label_train)\n",
    "\n",
    "clf.score(X_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i get several requests with petitions to save whales but never to stop the slaughter of babies in the wombs of mothers',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('bullshit multiplied by bullshit is still bullshit', 'NONE', 'AGAINST'),\n",
       " ('the point is bodily autonomy a born child can rely on other people and can live by itself',\n",
       "  'FAVOR',\n",
       "  'AGAINST'),\n",
       " ('the most horrific violence in america is the war on babies',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('people with a uterus can be pro choice people who have been pregnant can be pro choice people who lost a child can be prochoice',\n",
       "  'FAVOR',\n",
       "  'FAVOR'),\n",
       " ('those who deny women been raped abortion are the same ppl who tell rape victims they asked for it',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('and accepting with love any children arising from union of marriage or at least taking responsibility for life created',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('but of course today one have to be responsible you can kill your child instead',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('or these dumb assholes who sit on canadian streets with inaccurate disturbing pics',\n",
       "  'NONE',\n",
       "  'FAVOR'),\n",
       " ('when is ms c case been promising happening a court be asked adjudicate her claims',\n",
       "  'NONE',\n",
       "  'AGAINST')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = clf.predict(X_test)\n",
    "list(zip(text_test, test_preds, label_test))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47777998455257636"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "f1_score(label_test, test_preds, average=None, labels=['AGAINST','FAVOR','NONE'])\n",
    "\n",
    "# array([0.63157895, 0.41509434, 0.38666667])\n",
    "# Micro 0.525 Macro 0.47777998455257636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() missing 2 required positional arguments: 'ft_path' and 'corpus_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c72315b99576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: train() missing 2 required positional arguments: 'ft_path' and 'corpus_file'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
