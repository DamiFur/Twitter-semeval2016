{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import unidecode\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't import the data as directly downloaded from semeval because it gave me an \"unknown not utf-8 character\" so I imported it as a csv to an Excel and saved it again as train_utf.csv and it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"train_utf.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "testdata = pd.read_csv(\"test_utf.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "\n",
    "## Keep only the abortion tweets\n",
    "is_abortion = traindata['Target']==\"Legalization of Abortion\"\n",
    "is_abortion_test = testdata['Target']==\"Legalization of Abortion\"\n",
    "train_abortion = traindata[is_abortion]\n",
    "test_abortion = testdata[is_abortion_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TweetTokenizer basically unterstands arrows, smiley faces and weird punctuation\n",
    "tokenizer = TweetTokenizer(preserve_case=True, reduce_len=True, strip_handles=False)\n",
    "\n",
    "\n",
    "def my_preprocess(text, keep_hashtags=True):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "\n",
    "    ret = []\n",
    "    for tok in toks:\n",
    "        if tok[0] == \"#\" and not keep_hashtags:\n",
    "            continue\n",
    "        if tok[:4] == \"http\":\n",
    "            continue\n",
    "        if tok[0] == \"@\":\n",
    "            continue\n",
    "        # removing numbers\n",
    "        if tok.isnumeric():\n",
    "            continue\n",
    "        ret.append(unidecode.unidecode(tok.lower()))\n",
    "    return \" \".join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Train\n",
    "train_abortion['Text'] = train_abortion['Tweet'].apply(lambda x: my_preprocess(x))\n",
    "\n",
    "# Shifts the order on the original tweet list\n",
    "sample_train = train_abortion.sample(frac=1.0)\n",
    "\n",
    "text_train, label_train = sample_train['Text'], sample_train['Stance']\n",
    "\n",
    "## Test\n",
    "test_abortion['Text'] = test_abortion['Tweet'].apply(lambda x: my_preprocess(x))\n",
    "\n",
    "sample_test = test_abortion.sample(frac=1.0)\n",
    "\n",
    "text_test, label_test = sample_test['Text'], sample_test['Stance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a word count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3659 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    binary=True, min_df=0.002, max_df=0.55, ngram_range=(1, 4),\n",
    "    #stop_words=stopwords.words('spanish')\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(pd.concat([text_train,text_test]))\n",
    "X_train = X[:653]\n",
    "X_test = X[653:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a csv file with the label format that fasttext needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fasttext_train.txt\", 'w') as w:\n",
    "    for (text, label) in zip(text_train, label_train):\n",
    "        w.write(\"{} __label__{}\\n\".format(text, label))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best number of epochs in order not to overfit\n",
    "best_epoch = 0\n",
    "best_f1 = 0\n",
    "for epoch in [410, 420,430,440,450,460,470,480,490,500]:    \n",
    "    model = fasttext.train_supervised('fasttext_train.txt', lr=0.01, dim=300, epoch=epoch)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = []\n",
    "    for tweet in text_test:\n",
    "        predictions.append(model.predict(tweet))\n",
    "    pred_labels = [pred[0][0].replace('__label__','') for pred in predictions]\n",
    "    current_f1 = f1_score(label_test, pred_labels, average=\"macro\", labels=['AGAINST','FAVOR','NONE'])\n",
    "    if current_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_f1 = current_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fasttext.train_supervised('fasttext_train.txt', lr=0.01, dim=300, epoch=best_epoch)\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for tweet in text_test:\n",
    "    predictions.append(model.predict(tweet))\n",
    "\n",
    "pred_labels = [pred[0][0].replace('__label__','') for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7183908 , 0.47916667, 0.37931034])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(label_test, pred_labels, average=None, labels=['AGAINST','FAVOR','NONE'])\n",
    "\n",
    "# With 490 epochs an lr = 0.01, best result so far:\n",
    "# micro: 0.6071428571428571, macro: 0.5256226053639846, per_class=[0.7183908 , 0.47916667, 0.37931034]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate training file as needed by the fasttext lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "db = client[\"abortion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = open(\"fasttext_train_unsupervised.txt\", 'w')\n",
    "unique_tweets = set()\n",
    "for t in db.abortion.find({},{\"tweet.full_text\"}):\n",
    "    unique_tweets.add(t['tweet']['full_text'])\n",
    "\n",
    "for text in unique_tweets:\n",
    "    w.write(\"{}\\n\".format(text))\n",
    "\n",
    "for text in text_train:\n",
    "    w.write(\"{}\\n\".format(text))\n",
    "    \n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154726"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vectors = fasttext.train_supervised('fasttext_train_unsupervised.txt', lr=0.01, dim=300, epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds = [[0] * 300] * len(text_train)\n",
    "for idx, tweet in enumerate(text_train):\n",
    "    for word in tweet:\n",
    "        train_embeds[idx] += model_vectors[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = [[0] * 300] * len(text_test)\n",
    "for idx, tweet in enumerate(text_test):\n",
    "    for word in tweet:\n",
    "        test_embeds[idx] += model_vectors[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3659 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With word count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9127105666156202"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l1', class_weight='balanced', C=1.0, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, label_train)\n",
    "\n",
    "clf.score(X_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5821428571428572"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i thought they wanted less unwed mommas and less abortion . #confused #tcot #feminism #semst',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('prayers for babies urgent prayer one in lexington ky & two in dallas tx & in chattanooga tn life begins at conception #semst',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('watch out for censorship in your news and media ! #politicalrevolution #immigration #rednationrising #constitution #corruptmedia #semst',\n",
       "  'NONE',\n",
       "  'NONE'),\n",
       " (\"pro-choice =p ro-life . anti-choice = anti-life . don't play righteous when you're advocating the endangerment of women . #womensrights #semst\",\n",
       "  'FAVOR',\n",
       "  'FAVOR'),\n",
       " (\"yes . antis just don't make sense . #waronwomen #semst\", 'NONE', 'NONE'),\n",
       " ('i hope you all either enjoy the rugby or enjoy not enjoying the rugby #semst',\n",
       "  'NONE',\n",
       "  'AGAINST'),\n",
       " (\"i'm good like this . i've always been #semst\", 'NONE', 'NONE'),\n",
       " ('mathewsjeanne thank you your very #kind rt . god bless you #patriot . #babies matter #semst',\n",
       "  'AGAINST',\n",
       "  'AGAINST'),\n",
       " ('yes , an occasional hypocrite . i support #marriageequaility & abhor #semst',\n",
       "  'NONE',\n",
       "  'NONE'),\n",
       " ('was at the planned parenthood protest in #fitchburg today with the image of our lady of america #catholic #semst',\n",
       "  'NONE',\n",
       "  'AGAINST')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = clf.predict(X_test)\n",
    "list(zip(text_test, test_preds, label_test))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5427201885661455"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(label_test, test_preds, average=\"macro\", labels=['AGAINST','FAVOR','NONE'])\n",
    "\n",
    "# array([0.67109635, 0.47706422, 0.48      ])\n",
    "# Micro 0.5821428571428572 Macro 0.5427201885661455"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.557427258805513"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr_fasttext = LogisticRegression(penalty='l1', class_weight='balanced', C=1.0, n_jobs=-1)\n",
    "clf_lr_fasttext.fit(train_embeds, label_train)\n",
    "clf_lr_fasttext.score(train_embeds, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6928571428571428"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr_fasttext.score(test_embeds, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"well said . men are playing political football with women's right to have control over our bodies . #fail #semst\",\n",
       "  'AGAINST',\n",
       "  'FAVOR'),\n",
       " ('oh you dont like that im pro-choice . pftt . dont try to force me to be pro-life . fuck off #sorrynotsorry #semst',\n",
       "  'AGAINST',\n",
       "  'FAVOR'),\n",
       " ('just wanted to say that i appreciate the pro life stance . a lot of celebrities are afraid to show a bold stance #lfo #semst',\n",
       "  'AGAINST',\n",
       "  'AGAINST')]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_fasttext = clf_lr_fasttext.predict(test_embeds)\n",
    "list(zip(text_test, test_preds_fasttext, label_test))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3772006912138974"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(label_test, test_preds_fasttext, average='macro', labels=['AGAINST','FAVOR','NONE'])\n",
    "\n",
    "# array([0.81318681, 0.04255319, 0.27586207])\n",
    "# Micro 0.6928571428571428 Macro 0.3772006912138974\n",
    "\n",
    "#It's not predicting AGAINST to everything but it has a clear favouritism for majoritay class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step: check how well they perform accounting only the predictions with most confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
